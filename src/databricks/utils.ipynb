{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e053e1d0-7cc9-440e-b617-ed1aa8810928",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import requests\n",
    "\n",
    "\n",
    "from typing import Callable\n",
    "\n",
    "def meazure_duration(df_func: Callable, *args, **kwargs) -> tuple:\n",
    "    start = time.time()\n",
    "    success = True\n",
    "    try:\n",
    "        df = df_func(*args, **kwargs)\n",
    "        df.count()\n",
    "    except Exception as ex:\n",
    "        print(f\"Error measuring benchmark {df_func}: {ex}\")\n",
    "        success = False\n",
    "    finally:\n",
    "        return round(time.time() - start, 2), success\n",
    "\n",
    "def convert_size_bytes(size_bytes: int) -> float:\n",
    "    \"\"\"\n",
    "    Converts a size in bytes to a human readable string using SI units.\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(size_bytes, int):\n",
    "        size_bytes = sys.getsizeof(size_bytes)\n",
    "\n",
    "    if size_bytes == 0:\n",
    "        return \"0B\"\n",
    "\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "    p = math.pow(1024, i)\n",
    "    s = round(size_bytes / p, 2)\n",
    "    return round(size_bytes / p, 2)\n",
    "\n",
    "\n",
    "def estimate_df_size(df) -> float:\n",
    "    df.cache()\n",
    "    df.count()\n",
    "    catalyst_plan = df._jdf.queryExecution().logical()\n",
    "    size_bytes = spark._jsparkSession.sessionState().executePlan(catalyst_plan, df._jdf.queryExecution().mode()).optimizedPlan().stats().sizeInBytes()\n",
    "    df.unpersist()\n",
    "    return convert_size_bytes(size_bytes)\n",
    "\n",
    "def get_data_info(data_path: str):\n",
    "    df = spark.read.csv(data_path, header=True)\n",
    "    data = [{\n",
    "        \"column_count\": len(df.columns),\n",
    "        \"size\": estimate_df_size(df),\n",
    "        \"row_count\": df.count()\n",
    "    }]\n",
    "    return spark.createDataFrame(data).select(\"size\", \"row_count\", \"column_count\")\n",
    "\n",
    "def get_cluster_info():\n",
    "    host = f\"https://{spark.conf.get('spark.databricks.workspaceUrl')}\"\n",
    "    token = \"\"\n",
    "    headers = {\"Authorization\": f\"Bearer {token}\"}\n",
    "\n",
    "    cluster_id = spark.conf.get(\"spark.databricks.clusterUsageTags.clusterId\")\n",
    "\n",
    "    cluster_info = requests.get(\n",
    "        f\"{host}/api/2.0/clusters/get?cluster_id={cluster_id}\",\n",
    "        headers=headers\n",
    "    ).json()\n",
    "    node_type = cluster_info[\"node_type_id\"]\n",
    "    # instance_count = cluster_info[\"autoscale\"][\"max_workers\"]\n",
    "\n",
    "    node_types = requests.get(\n",
    "        f\"{host}/api/2.0/clusters/list-node-types\",\n",
    "        headers=headers\n",
    "    ).json()\n",
    "\n",
    "    node_spec = next(x for x in node_types[\"node_types\"] if x[\"node_type_id\"] == node_type)\n",
    "\n",
    "    cpu = node_spec[\"num_cores\"]\n",
    "    memory_gb = node_spec[\"memory_mb\"] / 1024\n",
    "\n",
    "    data = [{\n",
    "        \"cluster_instance_type\": node_type,\n",
    "        \"cluster_instance_cpu\": cpu,\n",
    "        \"cluster_instance_memory\": memory_gb,\n",
    "        \"cluster_instance_count\": 1\n",
    "    }]\n",
    "\n",
    "    return (\n",
    "        spark.createDataFrame(data)\n",
    "        .select(\"cluster_instance_type\", \"cluster_instance_cpu\", \"cluster_instance_memory\", \"cluster_instance_count\")\n",
    "    )\n",
    "\n",
    "def run_benchmark(task_name: str, task_func: callable, *task_args) -> list[tuple]:\n",
    "    print(f\"Running benchmark for {task_name}\")\n",
    "    return [\n",
    "        (task_name, *meazure_duration(task_func, *task_args))\n",
    "        for _ in range(MAX_EXECUTION_COUNT)\n",
    "    ]\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "utils",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
