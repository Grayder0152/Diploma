{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c6ed317-f7c1-44d3-b7fa-ff5f006a4d4c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as f\n",
    "\n",
    "class SparkBenchmark:\n",
    "    \"\"\"Scalable benchmark suite for Apache Spark with diverse task coverage.\"\"\"\n",
    "\n",
    "    def __init__(self, spark: SparkSession, tasks: list[str] = None):\n",
    "        if tasks is None:\n",
    "            tasks = [\"*\"]\n",
    "\n",
    "        self._spark = spark\n",
    "        self.tasks = {\n",
    "            bm_name: getattr(self, bm_name) for bm_name in dir(self)\n",
    "            if callable(getattr(self, bm_name)) and not bm_name.startswith(\"_\") and (bm_name in tasks or \"*\" in tasks)\n",
    "        }\n",
    "    def _read_multiple_csv_files(self, data_path: str):\n",
    "        \"\"\"Read multiple CSV files based on configuration.\"\"\"\n",
    "\n",
    "        return self._spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "    \n",
    "    def group_by_model(self, data_path: str):\n",
    "        \"\"\"\n",
    "        Benchmark type: Aggregation + statistics.\n",
    "        Measures group-by and aggregation kernel efficiency.\n",
    "        \"\"\"\n",
    "\n",
    "        df = self._read_multiple_csv_files(data_path)\n",
    "        result = (\n",
    "            df.groupBy(\"model\")\n",
    "            .agg(\n",
    "                f.mean(\"smart_5_raw\").alias(\"avg_smart_5_raw\"),\n",
    "                f.stddev(\"smart_5_raw\").alias(\"std_smart_5_raw\"),\n",
    "                f.countDistinct(\"serial_number\").alias(\"unique_disks\"),\n",
    "                f.sum(\"failure\").alias(\"failures_total\"),\n",
    "            )\n",
    "            .orderBy(f.desc(\"avg_smart_5_raw\"))\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    def union_and_aggregate(self, data_folders: list[str]):\n",
    "        \"\"\"\n",
    "        Benchmark type: Multi-file union + global reduction.\n",
    "        Tests concatenation (unionAll) performance and overall aggregation.\n",
    "        \"\"\"\n",
    "\n",
    "        if len(data_folders) < 2:\n",
    "            raise ValueError(\"At least two files are required for union test.\")\n",
    "\n",
    "        base_df = self._spark.read.csv(data_folders[0], header=True, inferSchema=True)\n",
    "        for data_path in data_folders[1:]:\n",
    "            next_df = self._spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "            base_df = base_df.unionByName(next_df, allowMissingColumns=True)\n",
    "\n",
    "        result = (\n",
    "            base_df.agg(\n",
    "                f.mean(\"smart_5_raw\").alias(\"mean_smart_5\"),\n",
    "                f.mean(\"smart_187_raw\").alias(\"mean_smart_187\"),\n",
    "                f.sum(\"failure\").alias(\"total_failures\"),\n",
    "                f.count(\"*\").alias(\"records_total\"),\n",
    "            )\n",
    "            .withColumn(\n",
    "                \"failure_rate\",\n",
    "                f.col(\"total_failures\") / f.col(\"records_total\"),\n",
    "            )\n",
    "        )\n",
    "        return result\n",
    "\n",
    "    def join_adjacent_days(self, data_folders: list[str]):\n",
    "        \"\"\"\n",
    "        Benchmark type: Join between adjacent files.\n",
    "        Tests join performance and shuffle behavior (Spark equivalent of Polars version).\n",
    "        \"\"\"\n",
    "\n",
    "        if len(data_folders) < 2:\n",
    "            raise ValueError(\"At least two files are required for join test.\")\n",
    "\n",
    "        base_df = (\n",
    "            self._spark.read.csv(data_folders[0], header=True, inferSchema=True)\n",
    "            .select(\"serial_number\", \"smart_5_raw\", \"date\")\n",
    "        )\n",
    "\n",
    "        for i, data_path in enumerate(data_folders[1:], start=1):\n",
    "            next_df = (\n",
    "                self._spark.read.csv(data_path, header=True, inferSchema=True)\n",
    "                .select(\n",
    "                    f.col(\"serial_number\").alias(\"serial_number_next\"),\n",
    "                    f.col(\"smart_5_raw\").alias(f\"smart_5_raw_next_{i}\"),\n",
    "                    f.col(\"date\").alias(f\"date_next_{i}\")\n",
    "                )\n",
    "            )\n",
    "\n",
    "            base_df = (\n",
    "                base_df.join(\n",
    "                    next_df,\n",
    "                    base_df.serial_number == next_df.serial_number_next,\n",
    "                    \"inner\"\n",
    "                )\n",
    "                .drop(\"serial_number_next\")\n",
    "            )\n",
    "\n",
    "        last_suffix = f\"_{i}\"\n",
    "        base_df = base_df.withColumn(\n",
    "            f\"smart_delta{last_suffix}\",\n",
    "            f.col(f\"smart_5_raw_next{last_suffix}\") - f.col(\"smart_5_raw\")\n",
    "        )\n",
    "\n",
    "        return base_df"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "spark_actions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
