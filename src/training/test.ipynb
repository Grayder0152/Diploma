{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-27T00:33:29.359791Z",
     "start_time": "2025-11-27T00:31:22.273206Z"
    }
   },
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "\n",
    "import joblib\n",
    "import polars as pl\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "\n",
    "from config import (\n",
    "    DATA_FOLDER, DURATION_POLARS_COL, DURATION_SPARK_COL,\n",
    "    CATEGORICAL_FEATURE, IS_SUCCESS_POLARS_COL, IS_SUCCESS_SPARK_COL,\n",
    "    FEATURES, MODELS_FOLDER, TEST_FILE_NAME, TRAIN_FILE_NAME\n",
    ")\n",
    "\n",
    "\n",
    "def choose_engine(row):\n",
    "    if row[IS_SUCCESS_POLARS_COL] == 0 and row[IS_SUCCESS_SPARK_COL] == 1:\n",
    "        return \"spark\"\n",
    "    if row[IS_SUCCESS_SPARK_COL] == 0 and row[IS_SUCCESS_POLARS_COL] == 1:\n",
    "        return \"polars\"\n",
    "    if row[IS_SUCCESS_SPARK_COL] == 0 and row[IS_SUCCESS_POLARS_COL] == 0:\n",
    "        return \"none\"\n",
    "    return \"polars\" if row[DURATION_POLARS_COL] < row[DURATION_SPARK_COL] else \"spark\"\n",
    "\n",
    "\n",
    "agg = (\n",
    "    pl.read_csv(os.path.join(DATA_FOLDER, f\"{TRAIN_FILE_NAME}.csv\"))\n",
    "    .group_by([*FEATURES, \"engine\"])\n",
    "    .agg([\n",
    "        pl.mean(\"duration\").alias(\"duration\"),\n",
    "        pl.min(\"success\").alias(\"success\")\n",
    "    ])\n",
    ")\n",
    "\n",
    "pivoted = agg.pivot(values=[\"duration\", \"success\"], index=FEATURES, on=\"engine\")\n",
    "\n",
    "clean_df = (\n",
    "    pivoted\n",
    "    .with_columns(pl.struct(pivoted.columns).map_elements(choose_engine).alias(\"label\"))\n",
    "    .with_columns([\n",
    "        pl.col(DURATION_POLARS_COL).log1p().alias(f\"{DURATION_POLARS_COL}_log\"),\n",
    "        pl.col(DURATION_SPARK_COL).log1p().alias(f\"{DURATION_SPARK_COL}_log\"),\n",
    "    ])\n",
    ")\n",
    "\n",
    "clean_df.write_csv(os.path.join(DATA_FOLDER, f\"{TRAIN_FILE_NAME}_cleaned_log.csv\"))\n",
    "\n",
    "\n",
    "def train_oom_classifier(df: pl.DataFrame, suc_column: str) -> Optional[CatBoostClassifier]:\n",
    "    uniq = df[suc_column].unique().to_list()\n",
    "    if len(uniq) == 1:\n",
    "        print(f\"Skipping classifier for {suc_column}, only one class: {uniq}\")\n",
    "        return None\n",
    "\n",
    "    model = CatBoostClassifier(\n",
    "        iterations=500,\n",
    "        depth=6,\n",
    "        learning_rate=0.05,\n",
    "        loss_function=\"Logloss\",\n",
    "        auto_class_weights=\"Balanced\",\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        df[FEATURES].to_pandas(),\n",
    "        df[suc_column].to_pandas(),\n",
    "        cat_features=CATEGORICAL_FEATURE,\n",
    "    )\n",
    "\n",
    "    joblib.dump(model, os.path.join(MODELS_FOLDER, f\"oom_{suc_column}_{TRAIN_FILE_NAME}_model.cbm\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "oom_polars_model = train_oom_classifier(clean_df, IS_SUCCESS_POLARS_COL)\n",
    "oom_spark_model = train_oom_classifier(clean_df, IS_SUCCESS_SPARK_COL)\n",
    "\n",
    "\n",
    "def train_log_regression(df: pl.DataFrame, suc_column: str, dur_column: str) -> CatBoostRegressor:\n",
    "    model = CatBoostRegressor(\n",
    "        iterations=1500,\n",
    "        depth=6,\n",
    "        learning_rate=0.03,\n",
    "        loss_function=\"RMSE\",\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    X = df.filter(pl.col(suc_column) == 1).select(FEATURES).to_pandas()\n",
    "    y = df.filter(pl.col(suc_column) == 1).select(f\"{dur_column}_log\").to_pandas()[f\"{dur_column}_log\"]\n",
    "\n",
    "    model.fit(\n",
    "        X,\n",
    "        y,\n",
    "        cat_features=CATEGORICAL_FEATURE\n",
    "    )\n",
    "\n",
    "    joblib.dump(model, os.path.join(MODELS_FOLDER, f\"logreg_{dur_column}_{TRAIN_FILE_NAME}_model.cbm\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "polars_time_model = train_log_regression(clean_df, IS_SUCCESS_POLARS_COL, DURATION_POLARS_COL)\n",
    "spark_time_model = train_log_regression(clean_df, IS_SUCCESS_SPARK_COL, DURATION_SPARK_COL)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sderevianko\\AppData\\Local\\Temp\\ipykernel_19140\\4144758026.py:38: MapWithoutReturnDtypeWarning: Calling `map_elements` without specifying `return_dtype` can lead to unpredictable results. Specify `return_dtype` to silence this warning.\n",
      "  .with_columns(pl.struct(pivoted.columns).map_elements(choose_engine).alias(\"label\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping classifier for success_spark, only one class: [1]\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
