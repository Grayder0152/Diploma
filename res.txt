Label 1 model:
# 1
iterations=2500,
depth=8,
learning_rate=0.3,
loss_function="Logloss",
auto_class_weights="Balanced"

Accuracy: 0.7555555555555555
Precision: 0.8422939068100359
Recall: 0.7555555555555555
F1-score: 0.7474442768560416
Confusion matrix:
[[20  0]
 [11 14]]
Classification report:
              precision    recall  f1-score   support

      polars       0.65      1.00      0.78        20
       spark       1.00      0.56      0.72        25

    accuracy                           0.76        45
   macro avg       0.82      0.78      0.75        45
weighted avg       0.84      0.76      0.75        45


# 2
iterations=5000,
depth=10,
learning_rate=0.03,
loss_function="Logloss",
auto_class_weights="Balanced"

Accuracy: 0.7777777777777778
Precision: 0.8518518518518517
Recall: 0.7777777777777778
F1-score: 0.7722222222222223
Confusion matrix:
[[20  0]
 [10 15]]
Classification report:
              precision    recall  f1-score   support

      polars       0.67      1.00      0.80        20
       spark       1.00      0.60      0.75        25

    accuracy                           0.78        45
   macro avg       0.83      0.80      0.78        45
weighted avg       0.85      0.78      0.77        45


# 3
iterations=5000,
depth=10,
learning_rate=0.03,
loss_function="Logloss",
auto_class_weights="Balanced",
l2_leaf_reg=6,
random_strength=1.8,
bootstrap_type="Bayesian",
bagging_temperature=0.3

Accuracy: 0.7555555555555555
Precision: 0.8422939068100359
Recall: 0.7555555555555555
F1-score: 0.7474442768560416
Confusion matrix:
[[20  0]
 [11 14]]
Classification report:
              precision    recall  f1-score   support

      polars       0.65      1.00      0.78        20
       spark       1.00      0.56      0.72        25

    accuracy                           0.76        45
   macro avg       0.82      0.78      0.75        45
weighted avg       0.84      0.76      0.75        45


# 4
iterations=5000,
depth=10,
learning_rate=0.05,
loss_function="Logloss",
auto_class_weights="Balanced"

Accuracy: 0.7777777777777778
Precision: 0.8518518518518517
Recall: 0.7777777777777778
F1-score: 0.7722222222222223
Confusion matrix:
[[20  0]
 [10 15]]
Classification report:
              precision    recall  f1-score   support

      polars       0.67      1.00      0.80        20
       spark       1.00      0.60      0.75        25

    accuracy                           0.78        45
   macro avg       0.83      0.80      0.78        45
weighted avg       0.85      0.78      0.77        45